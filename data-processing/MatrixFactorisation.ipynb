{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXGlD1RWeWOm",
    "outputId": "f5df01e9-233c-42ca-bd45-94bcb23e99e7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0at3yzYMQCY8",
    "outputId": "9193bfde-2549-4989-b916-2376a6f11568"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOnK8F1dLR6F",
    "outputId": "301ac706-e6d7-4344-dc53-a2af54b8f46a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hchinta1\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Requirement already satisfied: scikit-surprise in c:\\users\\hchinta1\\anaconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hchinta1\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hchinta1\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\hchinta1\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install scikit-surprise\n",
    "import os\n",
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.accuracy import rmse\n",
    "from collections import defaultdict\n",
    "from surprise import KNNBasic\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import accuracy\n",
    "from surprise import AlgoBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n5M280SQLR6F"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to load the ratings and movies datasets\n",
    "\n",
    "# dir = '/content/drive/MyDrive/CSE573-SWM-Movie-Recommender/DATA'\n",
    "def loadDataset():\n",
    "  ratings_df = pd.read_csv('./Data/ratings.csv')\n",
    "  movies_df = pd.read_csv('./Data/movies.csv')\n",
    "  \n",
    "  ratings_df.drop('timestamp',axis =1, inplace = True)\n",
    "\n",
    "  return ratings_df,movies_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7xXNM77ULR6G"
   },
   "outputs": [],
   "source": [
    "# Calculates the evaluations metrics Precision and Recall for each loop of cross validation\n",
    "\n",
    "def metricsAtK(predictions, k=10, threshold=3.5):\n",
    "\n",
    "    # dictionary to store user and the respective predicted ratings of the movies\n",
    "    user_predicted = defaultdict(list)\n",
    "    for u_id, _, rating_actual, rating_predicted, _ in predictions:\n",
    "        user_predicted[u_id].append((rating_predicted, rating_actual))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "\n",
    "    for u_id, u_ratings in user_predicted.items():\n",
    "        u_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Calculating actual values of the ratings\n",
    "        actual = sum((ratings_true >= threshold) for (_, ratings_true) in u_ratings)\n",
    "        # Calculating predicted values of the ratings\n",
    "        predicted = sum((estimate_value >= threshold) for (estimate_value, _) in u_ratings[:k])\n",
    "\n",
    "        # Calculating true positives and negatives\n",
    "        positive_true = sum(((ratings_true >= threshold) and (estimate_value >= threshold))\n",
    "                              for (estimate_value, ratings_true) in u_ratings[:k])\n",
    "        negative_true = sum(((ratings_true < threshold) and (estimate_value < threshold))\n",
    "                              for (estimate_value, ratings_true) in u_ratings[:k])\n",
    "        \n",
    "        # Calculating actual and predicted positives and negatives\n",
    "        positive_predicted = predicted if predicted != 0 else 1\n",
    "        negative_predicted = predicted if predicted != 1 else 0\n",
    "        positive_actual = actual if actual != 0 else 1\n",
    "        negative_actual = actual if actual != 1 else 0\n",
    "\n",
    "        # Calculating precision, recall and accuracy\n",
    "        precisions[u_id] = positive_true / positive_predicted\n",
    "        recalls[u_id] = positive_true / positive_actual\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A2AxjWMMLR6H"
   },
   "outputs": [],
   "source": [
    "def fit(model, ratings_data, num_of_splits=5):\n",
    "  # Generator object for k - cross validation\n",
    "  kf = KFold(n_splits=num_of_splits)\n",
    "  split_df = list()\n",
    "\n",
    "  i = 1\n",
    "  for train, test in kf.split(ratings_data):\n",
    "      predictions = model.fit(train).test(test)\n",
    "      rmse = accuracy.rmse(predictions, verbose=False)\n",
    "      mae = accuracy.mae(predictions, verbose=False)\n",
    "      precisions, recalls = metricsAtK(predictions, k=5, threshold=4)\n",
    "      precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "      recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "      f1_score = (2*precision*recall)/(precision+recall)\n",
    "      split_df.append([i,precision,recall,rmse,f1_score,mae])\n",
    "      i +=1\n",
    "\n",
    "  split_df = pd.DataFrame(split_df, columns=['Split', 'Precision', 'Recall', 'RMSE', 'F1 Score', 'MAE'])\n",
    "  return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4vH9bSBSYWVA"
   },
   "outputs": [],
   "source": [
    "def getSortedPredictions(predictions):\n",
    "    \n",
    "    sorted_predictions = defaultdict(list)    \n",
    "    for u_id, id, _, rating_predicted, _ in predictions:\n",
    "        sorted_predictions[u_id].append((id, rating_predicted))\n",
    "\n",
    "    for u_id, u_ratings in sorted_predictions.items():\n",
    "        u_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IRiii6tGYaUt"
   },
   "outputs": [],
   "source": [
    "def inference(model):\n",
    "  trainset = ratings_data.build_full_trainset()\n",
    "\n",
    "  # build_anti_testset will generate the entires for the movies which the user has not rated. i.e \n",
    "  # The completement of the user's ratings. It assumes the rating to be equal to the global mean of the ratings.\n",
    "  testset = trainset.build_anti_testset() \n",
    "\n",
    "  # Training the model with trainset and getting predictions using the generated testset\n",
    "  model.fit(trainset)\n",
    "  predictions = model.test(testset)\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eZZHVJyDYhw7"
   },
   "outputs": [],
   "source": [
    "# Post processing the predictions to produce the list of recommendations\n",
    "def getRecommendations(predictions, n=10):\n",
    "\n",
    "  # Getting sorted predictions\n",
    "  total = getSortedPredictions(predictions)\n",
    "\n",
    "  # Extracting only n number of movie predictions\n",
    "  for user_id, user_ratings in total.items():\n",
    "      total[user_id] = user_ratings[:n]\n",
    "\n",
    "  total_df = pd.DataFrame.from_dict(total)\n",
    "  total_df = total_df.transpose()\n",
    "\n",
    "  result = []\n",
    "  for user_id,user_ratings in total.items():\n",
    "    result.append(total_df.loc[user_id])\n",
    "\n",
    "  #Developing recommendations\n",
    "  recommendations = []\n",
    "  for i in result:\n",
    "    recommended_movieIds=[]\n",
    "    for x in range(0, n):\n",
    "      recommended_movieIds.append(i[x][0])\n",
    "    recommendations.append(recommended_movieIds)\n",
    "\n",
    "  recommendation_list = []\n",
    "  for i in recommendations:\n",
    "    df = movies_df[movies_df['movieId'].isin(i)]\n",
    "    temp = df['title'].tolist()\n",
    "    recommendation_list.append(temp)\n",
    "\n",
    "  recommendation_df = pd.DataFrame(recommendation_list)\n",
    "  return recommendation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPwzeBbLYkmG"
   },
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yTclmQEKYqOK"
   },
   "outputs": [],
   "source": [
    "ratings_df , movies_df = loadDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FA0ZuL-sYsdT"
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "ratings_keys = ['userId', 'movieId', 'rating']\n",
    "ratings_filter = ratings_df[ratings_keys]\n",
    "ratings_data = Dataset.load_from_df(ratings_filter, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4916RWGgY4pm"
   },
   "source": [
    "## Modeling Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf9494UPZFS3"
   },
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y4cVPgFTaD-R"
   },
   "outputs": [],
   "source": [
    "msd_knn = SVD(n_factors=30, n_epochs=20, lr_all=0.008, reg_all=0.08)\n",
    "#msd_preds = msd_knn.fit(trainset).test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "D5lra1EZaaxw",
    "outputId": "6ef8c44a-09c5-4cf9-cf47-22ff0392d5ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.558579</td>\n",
       "      <td>0.219046</td>\n",
       "      <td>0.863196</td>\n",
       "      <td>0.314688</td>\n",
       "      <td>0.662733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.567459</td>\n",
       "      <td>0.229017</td>\n",
       "      <td>0.864921</td>\n",
       "      <td>0.326332</td>\n",
       "      <td>0.663175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.553968</td>\n",
       "      <td>0.229794</td>\n",
       "      <td>0.869022</td>\n",
       "      <td>0.324840</td>\n",
       "      <td>0.667769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.234674</td>\n",
       "      <td>0.860797</td>\n",
       "      <td>0.330245</td>\n",
       "      <td>0.662138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.533745</td>\n",
       "      <td>0.211811</td>\n",
       "      <td>0.867367</td>\n",
       "      <td>0.303272</td>\n",
       "      <td>0.666370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Precision    Recall      RMSE  F1 Score       MAE\n",
       "0      1   0.558579  0.219046  0.863196  0.314688  0.662733\n",
       "1      2   0.567459  0.229017  0.864921  0.326332  0.663175\n",
       "2      3   0.553968  0.229794  0.869022  0.324840  0.667769\n",
       "3      4   0.557143  0.234674  0.860797  0.330245  0.662138\n",
       "4      5   0.533745  0.211811  0.867367  0.303272  0.666370"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating evaluation metrics Precision, Recall, F1-Score, RMSE, MAE for the ratings dataset\n",
    "msd_metrics = fit(msd_knn, ratings_data)\n",
    "msd_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FljSQ8pUamoF"
   },
   "outputs": [],
   "source": [
    "msd_predictions = inference(msd_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xfvgzCH1askr"
   },
   "outputs": [],
   "source": [
    "msd_df = getRecommendations(msd_predictions)\n",
    "msd_df.to_csv('msd_knn.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOzZ3xmVbCzK"
   },
   "source": [
    "### Using Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "by7JDCubbd0K"
   },
   "outputs": [],
   "source": [
    "# Defining the similarity options with pearson correlation.\n",
    "sim_options = {\n",
    "    'name': 'pearson'\n",
    "}\n",
    "\n",
    "pearson_knn = KNNBasic(k= 35, n_epochs=25,sim_options = sim_options)\n",
    "#cosine_preds = cosine_knn.fit(trainset).test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "P4Pv25Dkbg_b",
    "outputId": "7eb96859-ba38-4704-b127-a14a28c79814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>0.261927</td>\n",
       "      <td>0.975192</td>\n",
       "      <td>0.378415</td>\n",
       "      <td>0.753310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.674945</td>\n",
       "      <td>0.258220</td>\n",
       "      <td>0.978945</td>\n",
       "      <td>0.373534</td>\n",
       "      <td>0.754511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.654098</td>\n",
       "      <td>0.251986</td>\n",
       "      <td>0.982151</td>\n",
       "      <td>0.363815</td>\n",
       "      <td>0.758051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.648960</td>\n",
       "      <td>0.251235</td>\n",
       "      <td>0.974332</td>\n",
       "      <td>0.362236</td>\n",
       "      <td>0.750020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.245741</td>\n",
       "      <td>0.964915</td>\n",
       "      <td>0.355563</td>\n",
       "      <td>0.744201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Precision    Recall      RMSE  F1 Score       MAE\n",
       "0      1   0.681500  0.261927  0.975192  0.378415  0.753310\n",
       "1      2   0.674945  0.258220  0.978945  0.373534  0.754511\n",
       "2      3   0.654098  0.251986  0.982151  0.363815  0.758051\n",
       "3      4   0.648960  0.251235  0.974332  0.362236  0.750020\n",
       "4      5   0.642857  0.245741  0.964915  0.355563  0.744201"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating evaluation metrics Precision, Recall, F1-Score, RMSE, MAE for the ratings dataset\n",
    "pearson_metrics = fit(pearson_knn, ratings_data)\n",
    "pearson_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FrpKeA5bbjwQ",
    "outputId": "b39678cf-67ec-4b7e-dca6-e2a9c7b5c76f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pearson_predictions = inference(pearson_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "toq6ybHkbmN3"
   },
   "outputs": [],
   "source": [
    "\n",
    "pearson_df = getRecommendations(pearson_predictions)\n",
    "pearson_df.to_csv('pearson_knn.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN1PV4YhbrEC"
   },
   "source": [
    "### Using Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZkvJdPdDcD7n"
   },
   "outputs": [],
   "source": [
    "# Defining the similarity options with cosine similarity.\n",
    "sim_options = {\n",
    "    'name': 'cosine'\n",
    "}\n",
    "\n",
    "cosine_knn = KNNBasic(k= 35, n_epochs=25)\n",
    "#cosine_preds = cosine_knn.fit(trainset).test(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "kVIo18N1cGb7",
    "outputId": "d70c9c3e-d6e7-42da-e117-29af348a76f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.673852</td>\n",
       "      <td>0.266666</td>\n",
       "      <td>0.950745</td>\n",
       "      <td>0.382116</td>\n",
       "      <td>0.729525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.652244</td>\n",
       "      <td>0.263808</td>\n",
       "      <td>0.954977</td>\n",
       "      <td>0.375671</td>\n",
       "      <td>0.729906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.693634</td>\n",
       "      <td>0.266490</td>\n",
       "      <td>0.940647</td>\n",
       "      <td>0.385048</td>\n",
       "      <td>0.719891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.660902</td>\n",
       "      <td>0.263820</td>\n",
       "      <td>0.951512</td>\n",
       "      <td>0.377106</td>\n",
       "      <td>0.727735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.669235</td>\n",
       "      <td>0.273755</td>\n",
       "      <td>0.942311</td>\n",
       "      <td>0.388564</td>\n",
       "      <td>0.722014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Precision    Recall      RMSE  F1 Score       MAE\n",
       "0      1   0.673852  0.266666  0.950745  0.382116  0.729525\n",
       "1      2   0.652244  0.263808  0.954977  0.375671  0.729906\n",
       "2      3   0.693634  0.266490  0.940647  0.385048  0.719891\n",
       "3      4   0.660902  0.263820  0.951512  0.377106  0.727735\n",
       "4      5   0.669235  0.273755  0.942311  0.388564  0.722014"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating evaluation metrics Precision, Recall, F1-Score, RMSE, MAE for the ratings dataset\n",
    "cosine_metrics = fit(cosine_knn, ratings_data)\n",
    "cosine_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqDUr6f5cLnQ",
    "outputId": "be17a427-f1eb-40f6-8b37-bf2a7bb1c445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "cosine_predictions = inference(cosine_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ULy8iFtdcPAv"
   },
   "outputs": [],
   "source": [
    "cosine_df = getRecommendations(cosine_predictions)\n",
    "cosine_df.to_csv('cosine_knn.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
